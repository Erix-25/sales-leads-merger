import streamlit as st
import pandas as pd
import numpy as np
import re
import io
from datetime import datetime
from collections import defaultdict
import tempfile
import os

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="é”€å”®çº¿ç´¢åˆå¹¶å·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è®¾ç½®åº”ç”¨æ ‡é¢˜å’Œè¯´æ˜
st.title("ğŸ“Š é”€å”®çº¿ç´¢åˆå¹¶å·¥å…· - Webç‰ˆ")
st.markdown("---")

# åˆå§‹åŒ– session state
if 'df_merged' not in st.session_state:
    st.session_state.df_merged = None
if 'processing_log' not in st.session_state:
    st.session_state.processing_log = []

def add_log(message):
    """æ·»åŠ å¤„ç†æ—¥å¿—"""
    st.session_state.processing_log.append(f"{datetime.now().strftime('%H:%M:%S')} - {message}")

# ä¾§è¾¹æ é…ç½®
st.sidebar.header("âš™ï¸ é…ç½®é€‰é¡¹")

# 1. æ–‡ä»¶æ ¼å¼ä¿®å¤éƒ¨åˆ†ï¼ˆåŸ"æ”¹æ–‡ä»¶æ ¼å¼.ipynb"çš„åŠŸèƒ½ï¼‰
st.sidebar.subheader("1. æ–‡ä»¶æ ¼å¼ä¿®å¤")
uploaded_file = st.sidebar.file_uploader(
    "ä¸Šä¼ æ±½è½¦ä¹‹å®¶CSVæ–‡ä»¶",
    type=['csv'],
    help="ä¸Šä¼ éœ€è¦ä¿®å¤æ ¼å¼çš„æ±½è½¦ä¹‹å®¶CSVæ–‡ä»¶"
)

if uploaded_file is not None:
    st.sidebar.success(f"å·²ä¸Šä¼ : {uploaded_file.name}")
    
    # ä¿®å¤CSVæ ¼å¼çš„å‡½æ•°
    def fix_csv_format(file_content):
        """ä¿®å¤CSVæ ¼å¼é—®é¢˜"""
        lines = file_content.decode('utf-8-sig').splitlines()
        processed_lines = []
        
        for i, line in enumerate(lines):
            line = line.strip()
            
            if i == 0:
                processed_lines.append(line)
                continue
            
            if line.startswith('"') and line.endswith('"'):
                line = line[1:-1]
            
            line = line.replace('""', 'TEMP_QUOTE')
            parts = line.split(',')
            
            processed_parts = []
            for part in parts:
                if part.startswith('"') and part.endswith('"'):
                    part = part[1:-1]
                part = part.replace('TEMP_QUOTE', '"')
                processed_parts.append(part)
            
            processed_lines.append(','.join(processed_parts))
        
        return '\n'.join(processed_lines)
    
    # æ˜¾ç¤ºä¿®å¤é€‰é¡¹
    if st.sidebar.button("ä¿®å¤æ–‡ä»¶æ ¼å¼"):
        try:
            fixed_content = fix_csv_format(uploaded_file.getvalue())
            
            # æä¾›ä¸‹è½½ä¿®å¤åçš„æ–‡ä»¶
            st.sidebar.download_button(
                label="ä¸‹è½½ä¿®å¤åçš„æ–‡ä»¶",
                data=fixed_content,
                file_name=f"fixed_{uploaded_file.name}",
                mime="text/csv"
            )
            st.sidebar.success("æ–‡ä»¶æ ¼å¼ä¿®å¤å®Œæˆï¼")
        except Exception as e:
            st.sidebar.error(f"ä¿®å¤å¤±è´¥: {str(e)}")

# 2. é”€å”®çº¿ç´¢åˆå¹¶é…ç½®
st.sidebar.subheader("2. åˆå¹¶é…ç½®")

# æ–‡ä»¶ä¸Šä¼ éƒ¨åˆ†
col1, col2 = st.sidebar.columns(2)

with col1:
    yiche_file = st.file_uploader("æ˜“è½¦ç½‘æ–‡ä»¶", type=['xlsx', 'xls'])
    
with col2:
    autohome_file = st.file_uploader("æ±½è½¦ä¹‹å®¶æ–‡ä»¶", type=['csv'])

# é”€å”®é¡¾é—®é€‰æ‹©
st.sidebar.subheader("é”€å”®é¡¾é—®åˆ†é…")
consultants = {
    "é™ˆå©·": st.sidebar.checkbox("é™ˆå©·", value=True),
    "å¼ ç†å¹³": st.sidebar.checkbox("å¼ ç†å¹³", value=True),
    "é‚µæŒ¯è‰º": st.sidebar.checkbox("é‚µæŒ¯è‰º", value=True),
    "è€¿ä½¶": st.sidebar.checkbox("è€¿ä½¶", value=True),
    "ç¿ä½³è·ƒ": st.sidebar.checkbox("ç¿ä½³è·ƒ", value=False),
    "é™ˆæ°": st.sidebar.checkbox("é™ˆæ°", value=False)
}

# ç¬¬ä¸€æ¡çº¿ç´¢æŒ‡å®šé¡¾é—®
first_consultant = st.sidebar.selectbox(
    "ç¬¬ä¸€æ¡çº¿ç´¢æŒ‡å®šé¡¾é—®",
    ["è‡ªåŠ¨åˆ†é…", "é™ˆå©·", "å¼ ç†å¹³", "é‚µæŒ¯è‰º", "è€¿ä½¶"]
)

if first_consultant == "è‡ªåŠ¨åˆ†é…":
    first_consultant = ""

# ä¸»åŠŸèƒ½åŒº
tab1, tab2, tab3 = st.tabs(["ğŸ“ æ•°æ®ä¸Šä¼ ", "âš™ï¸ æ•°æ®å¤„ç†", "ğŸ“Š ç»“æœåˆ†æ"])

with tab1:
    st.header("æ•°æ®æ–‡ä»¶ä¸Šä¼ ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("æ˜“è½¦ç½‘æ–‡ä»¶")
        if yiche_file:
            try:
                df_yiche = pd.read_excel(yiche_file)
                st.success(f"âœ… æˆåŠŸè¯»å–æ˜“è½¦ç½‘æ–‡ä»¶ï¼Œå…± {len(df_yiche)} æ¡è®°å½•")
                st.dataframe(df_yiche.head(), use_container_width=True)
            except Exception as e:
                st.error(f"è¯»å–å¤±è´¥: {str(e)}")
        else:
            st.info("è¯·ä¸Šä¼ æ˜“è½¦ç½‘Excelæ–‡ä»¶")
    
    with col2:
        st.subheader("æ±½è½¦ä¹‹å®¶æ–‡ä»¶")
        if autohome_file:
            try:
                df_autohome = pd.read_csv(autohome_file)
                st.success(f"âœ… æˆåŠŸè¯»å–æ±½è½¦ä¹‹å®¶æ–‡ä»¶ï¼Œå…± {len(df_autohome)} æ¡è®°å½•")
                st.dataframe(df_autohome.head(), use_container_width=True)
            except Exception as e:
                st.error(f"è¯»å–å¤±è´¥: {str(e)}")
        else:
            st.info("è¯·ä¸Šä¼ æ±½è½¦ä¹‹å®¶CSVæ–‡ä»¶")

# å¤åˆ¶åŸè„šæœ¬çš„å¤„ç†å‡½æ•°ï¼ˆéœ€è¦ç¨ä½œä¿®æ”¹ï¼‰
def remove_after_slash(value):
    """å»é™¤å­—ç¬¦ä¸²ä¸­'/'ä¹‹åçš„å†…å®¹"""
    if pd.isna(value):
        return ""
    value_str = str(value).strip()
    if '/' in value_str:
        return value_str.split('/')[0].strip()
    return value_str

def get_consultant_unit(consultant_name):
    """è·å–é¡¾é—®æ‰€å±å•ä½"""
    if consultant_name in ["å¼ ç†å¹³", "é‚µæŒ¯è‰º", "è€¿ä½¶", "é™ˆå©·"]:
        return "ä¸Šæµ·å®‰å‰åæµæ±½è½¦æœåŠ¡æœ‰é™å…¬å¸"
    elif consultant_name in ["ç¿ä½³è·ƒ", "é™ˆæ°"]:
        return "å®‰å‰åæµé”€å”®éƒ¨"
    return ""

def normalize_car_series(car_series, default_value="æ˜‚ç§‘å¨PLUS", original_source=None):
    """æ ‡å‡†åŒ–è½¦ç³»åç§°"""
    # è¿™é‡Œéœ€è¦å¤åˆ¶åŸè„šæœ¬çš„æ˜ å°„é€»è¾‘
    # ç”±äºç¯‡å¹…é™åˆ¶ï¼Œè¿™é‡Œç®€ç•¥å¤„ç†
    if pd.isna(car_series) or str(car_series).strip() == '':
        return default_value
    return str(car_series).strip()

# ä¸»è¦çš„åˆå¹¶å‡½æ•°
def process_merge(df_yiche, df_autohome, consultants, first_consultant):
    """å¤„ç†åˆå¹¶é€»è¾‘"""
    results = []
    
    # è¿™é‡Œéœ€è¦å¤åˆ¶åŸè„šæœ¬çš„å®Œæ•´å¤„ç†é€»è¾‘
    # ç”±äºä»£ç è¾ƒé•¿ï¼Œè¿™é‡Œåªå±•ç¤ºæ¡†æ¶
    
    # å¤„ç†æ˜“è½¦ç½‘æ•°æ®
    if df_yiche is not None:
        for idx, row in df_yiche.iterrows():
            name = remove_after_slash(row.get('å®¢æˆ·å§“å', ''))
            phone = remove_after_slash(row.get('å®¢æˆ·å·ç ', ''))
            
            if pd.isna(name) or pd.isna(phone) or name == '' or phone == '':
                continue
                
            # å…¶ä»–å¤„ç†é€»è¾‘...
            results.append({
                'å§“å': name,
                'æ‰‹æœºå·': phone,
                'æ„å‘è½¦ç³»': normalize_car_series(row.get('çº¿ç´¢æ„å‘è½¦å‹è½¦ç³»', '')),
                'é”€å”®é¡¾é—®': '',
                'å•ä½': '',
                'çº¿ç´¢æ¥æº': 'æ˜“è½¦'
            })
    
    # å¤„ç†æ±½è½¦ä¹‹å®¶æ•°æ®
    if df_autohome is not None:
        for idx, row in df_autohome.iterrows():
            name = remove_after_slash(row.get('å®¢æˆ·å§“å', ''))
            phone = remove_after_slash(row.get('å®¢æˆ·æ‰‹æœº', ''))
            
            if pd.isna(name) or pd.isna(phone) or name == '' or phone == '':
                continue
                
            # å…¶ä»–å¤„ç†é€»è¾‘...
            results.append({
                'å§“å': name,
                'æ‰‹æœºå·': phone,
                'æ„å‘è½¦ç³»': normalize_car_series(row.get('æ„å‘è½¦ç³»', '')),
                'é”€å”®é¡¾é—®': '',
                'å•ä½': '',
                'çº¿ç´¢æ¥æº': 'æ±½è½¦ä¹‹å®¶'
            })
    
    # åˆå¹¶ç»“æœ
    df = pd.DataFrame(results)
    
    # å»é‡
    before_dedup = len(df)
    df = df.drop_duplicates(subset=['æ‰‹æœºå·'], keep='first')
    after_dedup = len(df)
    
    add_log(f"å»é‡: {before_dedup} -> {after_dedup} æ¡è®°å½•")
    
    return df

with tab2:
    st.header("æ•°æ®å¤„ç†")
    
    if yiche_file is not None or autohome_file is not None:
        if st.button("ğŸš€ å¼€å§‹åˆå¹¶å¤„ç†", type="primary"):
            with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
                try:
                    # è¯»å–æ•°æ®
                    df_yiche = pd.read_excel(yiche_file) if yiche_file else None
                    df_autohome = pd.read_csv(autohome_file) if autohome_file else None
                    
                    # å¤„ç†åˆå¹¶
                    df_result = process_merge(df_yiche, df_autohome, consultants, first_consultant)
                    
                    # ä¿å­˜åˆ°session state
                    st.session_state.df_merged = df_result
                    
                    # æ˜¾ç¤ºå¤„ç†æ—¥å¿—
                    st.success("âœ… æ•°æ®å¤„ç†å®Œæˆï¼")
                    
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
    else:
        st.info("è¯·å…ˆä¸Šä¼ éœ€è¦å¤„ç†çš„æ–‡ä»¶")

with tab3:
    st.header("ç»“æœåˆ†æä¸ä¸‹è½½")
    
    if st.session_state.df_merged is not None:
        df = st.session_state.df_merged
        
        # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
        st.subheader("ğŸ“‹ æ•°æ®é¢„è§ˆ")
        st.dataframe(df.head(20), use_container_width=True)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“Š åŸºæœ¬ç»Ÿè®¡")
            st.metric("æ€»è®°å½•æ•°", len(df))
            st.metric("å»é‡å‰è®°å½•æ•°", "å¾…è¡¥å……")
            
        with col2:
            st.subheader("ğŸ” è½¦ç³»ç»Ÿè®¡")
            car_stats = df['æ„å‘è½¦ç³»'].value_counts()
            st.bar_chart(car_stats)
        
        # æä¾›ä¸‹è½½
        st.subheader("ğŸ’¾ ä¸‹è½½ç»“æœ")
        
        # è½¬æ¢ä¸ºExcel
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='åˆå¹¶ç»“æœ')
        output.seek(0)
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½Excelæ–‡ä»¶",
            data=output,
            file_name=f"CRSçº¿ç´¢_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    else:
        st.info("è¯·å…ˆå¤„ç†æ•°æ®ä»¥æŸ¥çœ‹ç»“æœ")

# é¡µè„š
st.markdown("---")
st.caption("é”€å”®çº¿ç´¢åˆå¹¶å·¥å…· v1.0 | æŠ€æœ¯æ”¯æŒ")